---
layout: post
title: "Understanding JMH: Java Microbenchmarking Made Simple"
date: 2025-10-26
---

<p>
In the world of software development, performance matters. But how do we accurately measure and compare the performance of different implementations? This is where JMH (Java Microbenchmark Harness) comes into play. In this post, we'll explore JMH through a practical example of benchmarking trace ID generation methods.
</p>

<h2>What is JMH?</h2>

<p>
JMH is a Java harness for building, running, and analyzing nano/micro/milli/macro benchmarks written in Java and other languages targeting the JVM. It was developed by the OpenJDK team and is used extensively in the JDK itself to perform performance testing.
</p>

<h2>Setting Up JMH with Gradle</h2>

<p>
To get started with JMH, you'll need to add the necessary dependencies to your build configuration. Here's how to set it up in a Gradle project:
</p>

{% highlight gradle %}
plugins {
    id 'java'
    id 'me.champeau.jmh' version '0.7.1'
    id 'io.morethan.jmhreport' version '0.9.0'
}

dependencies {
    implementation 'org.openjdk.jmh:jmh-core:1.37'
    implementation 'org.openjdk.jmh:jmh-generator-annprocess:1.37'
}

jmh {
    resultFormat = 'JSON'
    resultsFile = layout.buildDirectory.file('reports/jmh/results.json').get().asFile
    jmhVersion = '1.37'
    timeUnit = 'ns'
    threads = project.hasProperty('jmh.threads') ? project.property('jmh.threads').toInteger() : 1
}
{% endhighlight %}

<h2>Writing JMH Benchmarks</h2>

<p>
Let's look at a real-world example where we benchmark two different approaches to generating trace IDs: using UUID and using OpenTelemetry's IdGenerator.
</p>

{% highlight java %}
@BenchmarkMode({Mode.AverageTime, Mode.Throughput})
@OutputTimeUnit(TimeUnit.NANOSECONDS)
@State(Scope.Thread)
@Warmup(iterations = 5, time = 1)
@Measurement(iterations = 10, time = 1)
@Fork(2)
public class TraceIdGeneratorBenchmark {
    
    private IdGenerator otelIdGenerator;

    @Setup
    public void setup() {
        otelIdGenerator = IdGenerator.random();
    }

    @Benchmark
    public void uuidBasedTraceId(Blackhole blackhole) {
        String traceId = UUID.randomUUID().toString();
        blackhole.consume(traceId);
    }

    @Benchmark
    public void openTelemetryTraceId(Blackhole blackhole) {
        String traceId = otelIdGenerator.generateTraceId();
        blackhole.consume(traceId);
    }
}
{% endhighlight %}

<h2>Understanding JMH Annotations</h2>

<p>Let's break down the key JMH annotations:</p>

<ul>
    <li><strong>@BenchmarkMode</strong>: Specifies what to measure. In our example, we measure both average time and throughput.</li>
    <li><strong>@OutputTimeUnit</strong>: Defines the unit for the results (nanoseconds in our case).</li>
    <li><strong>@State</strong>: Defines the scope of our benchmark state (Thread scope means each thread has its own copy).</li>
    <li><strong>@Warmup</strong>: Specifies warmup iterations to get the JVM into a steady state.</li>
    <li><strong>@Measurement</strong>: Defines how many measurement iterations to perform.</li>
    <li><strong>@Fork</strong>: Indicates how many separate JVM forks to use (helps eliminate external factors).</li>
</ul>

<h2>Running the Benchmark Project</h2>

<p>
Let's walk through setting up and running our trace ID generator benchmark project:
</p>

<h3>Project Setup</h3>

{% highlight bash %}
# Clone the repository
git clone https://github.com/GSSwain/benchmark-trace-id-generator.git
cd benchmark-trace-id-generator

# Run the benchmark with single thread
./gradlew clean jmh

# Run with multiple threads (e.g., 10 threads)
./gradlew clean jmh -Pjmh.threads=10

# Generate html report
./gradlew clean jmhReport
{% endhighlight %}

<h3>Understanding the Project Structure</h3>

<p>The benchmark project includes:</p>
<ul>
    <li>JMH configuration in build.gradle</li>
    <li>Benchmark implementation in src/jmh/java</li>
    <li>Two trace ID generation methods:
        <ul>
            <li>UUID-based: Using Java's built-in UUID generator</li>
            <li>OpenTelemetry: Using OpenTelemetry's RandomIdGenerator</li>
        </ul>
    </li>
</ul>

<h2>Analyzing Benchmark Results</h2>

<h3>Single-Thread Performance (JDK 25)</h3>

<table class="performance-table">
<thead>
<tr>
    <th>Implementation</th>
    <th class="metric-col">Average Time (ns)</th>
    <th class="metric-col">Throughput (M ops/s)</th>
</tr>
</thead>
<tbody>
<tr>
    <td class="impl-cell highlight-otel">OpenTelemetry</td>
    <td class="metric-cell">14.321 ±0.130</td>
    <td class="metric-cell">69.8 ±0.6</td>
</tr>
<tr>
    <td class="impl-cell">UUID</td>
    <td class="metric-cell">247.141 ±8.476</td>
    <td class="metric-cell">4.0 ±0.1</td>
</tr>
</tbody>
</table>

<h3>Multi-Thread Performance (10 Threads, JDK 25)</h3>

<table class="performance-table">
<thead>
<tr>
    <th>Implementation</th>
    <th class="metric-col">Average Time (ns)</th>
    <th class="metric-col">Throughput (M ops/s)</th>
</tr>
</thead>
<tbody>
<tr>
    <td class="impl-cell highlight-otel">OpenTelemetry</td>
    <td class="metric-cell">24.967 ±1.525</td>
    <td class="metric-cell">400.5 ±24.4</td>
</tr>
<tr>
    <td class="impl-cell">UUID</td>
    <td class="metric-cell">3,761.317 ±65.991</td>
    <td class="metric-cell">2.7 ±0.1</td>
</tr>
</tbody>
</table>

<style>
.performance-table {
    width: 100%;
    border-collapse: collapse;
    margin: 20px 0;
    font-size: 15px;
    border: 1px solid #ddd;
}

.performance-table th,
.performance-table td {
    padding: 12px;
    text-align: right;
    border: 1px solid #ddd;
}

.performance-table th {
    background-color: #f5f5f5;
    font-weight: bold;
    text-align: center;
}

.performance-table .impl-cell {
    text-align: left;
}

.performance-table .metric-col {
    width: 33%;
}

.performance-table .metric-cell {
    font-family: monospace;
}

.performance-table .highlight-otel {
    background-color: #e8f5e9;
}

.performance-table tr:hover {
    background-color: #f8f9fa;
}
</style>

<h3>Interpreting These Results</h3>

<p>Let's break down what these numbers tell us:</p>

<h4>1. Single-Thread Analysis</h4>
<ul>
    <li><strong>Average Time:</strong>
        <ul>
            <li>OpenTelemetry: ~14.3 nanoseconds per operation</li>
            <li>UUID: ~247.1 nanoseconds per operation</li>
            <li>OpenTelemetry is approximately 17x faster</li>
        </ul>
    </li>
    <li><strong>Throughput:</strong>
        <ul>
            <li>OpenTelemetry: ~69.8 million ops/second</li>
            <li>UUID: ~4.0 million ops/second</li>
        </ul>
    </li>
</ul>

<h4>2. Multi-Thread Analysis (10 Threads)</h4>
<ul>
    <li><strong>Average Time:</strong>
        <ul>
            <li>OpenTelemetry: Only increases to ~25 nanoseconds (1.7x increase)</li>
            <li>UUID: Jumps to ~3,761 nanoseconds (15x increase)</li>
            <li>OpenTelemetry is now 150x faster</li>
        </ul>
    </li>
    <li><strong>Throughput:</strong>
        <ul>
            <li>OpenTelemetry: Increases to ~400.5 million ops/second (excellent scaling)</li>
            <li>UUID: Decreases to ~2.7 million ops/second (poor scaling)</li>
        </ul>
    </li>
</ul>

<h4>3. Key Observations</h4>
<ul>
    <li><strong>Thread Scaling:</strong>
        <ul>
            <li>OpenTelemetry shows excellent thread scaling (6x throughput improvement with 10 threads)</li>
            <li>UUID shows poor thread scaling (throughput actually decreases)</li>
        </ul>
    </li>
    <li><strong>Consistency:</strong>
        <ul>
            <li>OpenTelemetry has very small error margins (±0.130 to ±1.525)</li>
            <li>UUID shows larger variations (±8.476 to ±65.991)</li>
        </ul>
    </li>
</ul>

<p>
For a complete breakdown of the results across different JDK versions and a deeper analysis of the real-world impact, please see the follow-up post: <a href="/2025/11/15/performance-analysis-trace-id-generation.html">Trace ID Generation: A Performance Analysis of UUID vs. OpenTelemetry</a>.
</p>

<h2>Best Practices</h2>

<p>When writing JMH benchmarks, keep these points in mind:</p>

<ul>
    <li>Use <strong>Blackhole.consume()</strong> to prevent dead code elimination</li>
    <li>Include proper warmup iterations to ensure JVM optimization</li>
    <li>Run multiple forks to get statistically significant results</li>
    <li>Consider external factors like garbage collection and JIT compilation</li>
    <li>Document your benchmark environment (JVM version, available processors, etc.)</li>
</ul>

<h2>Conclusion</h2>

<p>
JMH is a powerful tool for measuring and comparing code performance on the JVM. While it requires careful setup and interpretation, it provides valuable insights into code performance characteristics. Remember that microbenchmarks should be one of many tools in your performance testing arsenal, alongside profiling and real-world performance testing.
</p>

<p>
The example used in this post can be found in the <a href="https://github.com/GSSwain/benchmark-trace-id-generator">benchmark-trace-id-generator</a> repository.
</p>