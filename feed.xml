<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://gsswain.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://gsswain.com/" rel="alternate" type="text/html" /><updated>2025-10-26T08:53:58+00:00</updated><id>https://gsswain.com/feed.xml</id><title type="html">Girija Swain</title><subtitle>15+ years of experience solving complex business problems through innovative  technology solutions and exceptional leadership. Specializing in cloud-native  architectures, microservices, and leading high-performing engineering teams.</subtitle><entry><title type="html">Understanding JMH: Java Microbenchmarking Made Simple</title><link href="https://gsswain.com/2025/10/26/understanding-jmh-java-microbenchmarking.html" rel="alternate" type="text/html" title="Understanding JMH: Java Microbenchmarking Made Simple" /><published>2025-10-26T00:00:00+00:00</published><updated>2025-10-26T00:00:00+00:00</updated><id>https://gsswain.com/2025/10/26/understanding-jmh-java-microbenchmarking</id><content type="html" xml:base="https://gsswain.com/2025/10/26/understanding-jmh-java-microbenchmarking.html"><![CDATA[<p>
In the world of software development, performance matters. But how do we accurately measure and compare the performance of different implementations? This is where JMH (Java Microbenchmark Harness) comes into play. In this post, we'll explore JMH through a practical example of benchmarking trace ID generation methods.
</p>

<h2>What is JMH?</h2>

<p>
JMH is a Java harness for building, running, and analyzing nano/micro/milli/macro benchmarks written in Java and other languages targeting the JVM. It was developed by the OpenJDK team and is used extensively in the JDK itself to perform performance testing.
</p>

<h2>Setting Up JMH with Gradle</h2>

<p>
To get started with JMH, you'll need to add the necessary dependencies to your build configuration. Here's how to set it up in a Gradle project:
</p>

<figure class="highlight"><pre><code class="language-gradle" data-lang="gradle"><span class="n">plugins</span> <span class="o">{</span>
    <span class="n">id</span> <span class="s1">'java'</span>
    <span class="n">id</span> <span class="s1">'me.champeau.jmh'</span> <span class="n">version</span> <span class="s1">'0.7.1'</span>
    <span class="n">id</span> <span class="s1">'io.morethan.jmhreport'</span> <span class="n">version</span> <span class="s1">'0.9.0'</span>
<span class="o">}</span>

<span class="k">dependencies</span> <span class="o">{</span>
    <span class="n">implementation</span> <span class="s1">'org.openjdk.jmh:jmh-core:1.37'</span>
    <span class="n">implementation</span> <span class="s1">'org.openjdk.jmh:jmh-generator-annprocess:1.37'</span>
<span class="o">}</span>

<span class="n">jmh</span> <span class="o">{</span>
    <span class="n">resultFormat</span> <span class="o">=</span> <span class="s1">'JSON'</span>
    <span class="n">resultsFile</span> <span class="o">=</span> <span class="n">layout</span><span class="o">.</span><span class="na">buildDirectory</span><span class="o">.</span><span class="na">file</span><span class="o">(</span><span class="s1">'reports/jmh/results.json'</span><span class="o">).</span><span class="na">get</span><span class="o">().</span><span class="na">asFile</span>
    <span class="n">jmhVersion</span> <span class="o">=</span> <span class="s1">'1.37'</span>
    <span class="n">timeUnit</span> <span class="o">=</span> <span class="s1">'ns'</span>
    <span class="n">threads</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="na">hasProperty</span><span class="o">(</span><span class="s1">'jmh.threads'</span><span class="o">)</span> <span class="o">?</span> <span class="n">project</span><span class="o">.</span><span class="na">property</span><span class="o">(</span><span class="s1">'jmh.threads'</span><span class="o">).</span><span class="na">toInteger</span><span class="o">()</span> <span class="o">:</span> <span class="mi">1</span>
<span class="o">}</span></code></pre></figure>

<h2>Writing JMH Benchmarks</h2>

<p>
Let's look at a real-world example where we benchmark two different approaches to generating trace IDs: using UUID and using OpenTelemetry's IdGenerator.
</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nd">@BenchmarkMode</span><span class="o">({</span><span class="nc">Mode</span><span class="o">.</span><span class="na">AverageTime</span><span class="o">,</span> <span class="nc">Mode</span><span class="o">.</span><span class="na">Throughput</span><span class="o">})</span>
<span class="nd">@OutputTimeUnit</span><span class="o">(</span><span class="nc">TimeUnit</span><span class="o">.</span><span class="na">NANOSECONDS</span><span class="o">)</span>
<span class="nd">@State</span><span class="o">(</span><span class="nc">Scope</span><span class="o">.</span><span class="na">Thread</span><span class="o">)</span>
<span class="nd">@Warmup</span><span class="o">(</span><span class="n">iterations</span> <span class="o">=</span> <span class="mi">5</span><span class="o">,</span> <span class="n">time</span> <span class="o">=</span> <span class="mi">1</span><span class="o">)</span>
<span class="nd">@Measurement</span><span class="o">(</span><span class="n">iterations</span> <span class="o">=</span> <span class="mi">10</span><span class="o">,</span> <span class="n">time</span> <span class="o">=</span> <span class="mi">1</span><span class="o">)</span>
<span class="nd">@Fork</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">TraceIdGeneratorBenchmark</span> <span class="o">{</span>
    
    <span class="kd">private</span> <span class="nc">IdGenerator</span> <span class="n">otelIdGenerator</span><span class="o">;</span>

    <span class="nd">@Setup</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setup</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">otelIdGenerator</span> <span class="o">=</span> <span class="nc">IdGenerator</span><span class="o">.</span><span class="na">random</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="nd">@Benchmark</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">uuidBasedTraceId</span><span class="o">(</span><span class="nc">Blackhole</span> <span class="n">blackhole</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">String</span> <span class="n">traceId</span> <span class="o">=</span> <span class="no">UUID</span><span class="o">.</span><span class="na">randomUUID</span><span class="o">().</span><span class="na">toString</span><span class="o">();</span>
        <span class="n">blackhole</span><span class="o">.</span><span class="na">consume</span><span class="o">(</span><span class="n">traceId</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="nd">@Benchmark</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">openTelemetryTraceId</span><span class="o">(</span><span class="nc">Blackhole</span> <span class="n">blackhole</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">String</span> <span class="n">traceId</span> <span class="o">=</span> <span class="n">otelIdGenerator</span><span class="o">.</span><span class="na">generateTraceId</span><span class="o">();</span>
        <span class="n">blackhole</span><span class="o">.</span><span class="na">consume</span><span class="o">(</span><span class="n">traceId</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<h2>Understanding JMH Annotations</h2>

<p>Let's break down the key JMH annotations:</p>

<ul>
    <li><strong>@BenchmarkMode</strong>: Specifies what to measure. In our example, we measure both average time and throughput.</li>
    <li><strong>@OutputTimeUnit</strong>: Defines the unit for the results (nanoseconds in our case).</li>
    <li><strong>@State</strong>: Defines the scope of our benchmark state (Thread scope means each thread has its own copy).</li>
    <li><strong>@Warmup</strong>: Specifies warmup iterations to get the JVM into a steady state.</li>
    <li><strong>@Measurement</strong>: Defines how many measurement iterations to perform.</li>
    <li><strong>@Fork</strong>: Indicates how many separate JVM forks to use (helps eliminate external factors).</li>
</ul>

<h2>Running the Benchmark Project</h2>

<p>
Let's walk through setting up and running our trace ID generator benchmark project:
</p>

<h3>Project Setup</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Clone the repository</span>
git clone https://github.com/GSSwain/benchmark-trace-id-generator.git
<span class="nb">cd </span>benchmark-trace-id-generator

<span class="c"># Run the benchmark with single thread</span>
./gradlew clean jmh

<span class="c"># Run with multiple threads (e.g., 10 threads)</span>
./gradlew clean jmh <span class="nt">-Pjmh</span>.threads<span class="o">=</span>10

<span class="c"># Generate html report</span>
./gradlew clean jmhReport</code></pre></figure>

<h3>Understanding the Project Structure</h3>

<p>The benchmark project includes:</p>
<ul>
    <li>JMH configuration in build.gradle</li>
    <li>Benchmark implementation in src/jmh/java</li>
    <li>Two trace ID generation methods:
        <ul>
            <li>UUID-based: Using Java's built-in UUID generator</li>
            <li>OpenTelemetry: Using OpenTelemetry's RandomIdGenerator</li>
        </ul>
    </li>
</ul>

<h2>Analyzing Benchmark Results</h2>

<h3>Single-Thread Performance (JDK 25)</h3>

<table class="performance-table">
<thead>
<tr>
    <th>Implementation</th>
    <th>Average Time (ns)</th>
    <th>Throughput (ops/ns)</th>
</tr>
</thead>
<tbody>
<tr>
    <td class="impl-cell highlight-otel">OpenTelemetry</td>
    <td class="metric-cell">14.321 ±0.130</td>
    <td class="metric-cell">0.069 ±0.001</td>
</tr>
<tr>
    <td class="impl-cell">UUID</td>
    <td class="metric-cell">247.141 ±8.476</td>
    <td class="metric-cell">0.004 ±0.001</td>
</tr>
</tbody>
</table>

<h3>Multi-Thread Performance (10 Threads, JDK 25)</h3>

<table class="performance-table">
<thead>
<tr>
    <th>Implementation</th>
    <th>Average Time (ns)</th>
    <th>Throughput (ops/ns)</th>
</tr>
</thead>
<tbody>
<tr>
    <td class="impl-cell highlight-otel">OpenTelemetry</td>
    <td class="metric-cell">24.967 ±1.525</td>
    <td class="metric-cell">0.420 ±0.007</td>
</tr>
<tr>
    <td class="impl-cell">UUID</td>
    <td class="metric-cell">3,761.317 ±65.991</td>
    <td class="metric-cell">0.003 ±0.001</td>
</tr>
</tbody>
</table>

<style>
.performance-table {
    width: 100%;
    border-collapse: collapse;
    margin: 20px 0;
    font-size: 15px;
    border: 1px solid #ddd;
}

.performance-table th,
.performance-table td {
    padding: 12px;
    text-align: right;
    border: 1px solid #ddd;
}

.performance-table th {
    background-color: #f5f5f5;
    font-weight: bold;
    text-align: center;
}

.performance-table .impl-cell {
    text-align: left;
}

.performance-table .metric-cell {
    font-family: monospace;
}

.performance-table .highlight-otel {
    background-color: #e8f5e9;
}

.performance-table tr:hover {
    background-color: #f8f9fa;
}
</style>

<h3>Interpreting These Results</h3>

<p>Let's break down what these numbers tell us:</p>

<h4>1. Single-Thread Analysis</h4>
<ul>
    <li><strong>Average Time:</strong>
        <ul>
            <li>OpenTelemetry: ~14.3 nanoseconds per operation</li>
            <li>UUID: ~247.1 nanoseconds per operation</li>
            <li>OpenTelemetry is approximately 17x faster</li>
        </ul>
    </li>
    <li><strong>Throughput:</strong>
        <ul>
            <li>OpenTelemetry: 0.069 operations per nanosecond (69 million ops/second)</li>
            <li>UUID: 0.004 operations per nanosecond (4 million ops/second)</li>
        </ul>
    </li>
</ul>

<h4>2. Multi-Thread Analysis (10 Threads)</h4>
<ul>
    <li><strong>Average Time:</strong>
        <ul>
            <li>OpenTelemetry: Only increases to ~25 nanoseconds (1.7x increase)</li>
            <li>UUID: Jumps to ~3,761 nanoseconds (15x increase)</li>
            <li>OpenTelemetry is now 150x faster</li>
        </ul>
    </li>
    <li><strong>Throughput:</strong>
        <ul>
            <li>OpenTelemetry: Increases to 0.420 ops/ns (excellent scaling)</li>
            <li>UUID: Decreases to 0.003 ops/ns (poor scaling)</li>
        </ul>
    </li>
</ul>

<h4>3. Key Observations</h4>
<ul>
    <li><strong>Thread Scaling:</strong>
        <ul>
            <li>OpenTelemetry shows excellent thread scaling (6x throughput improvement with 10 threads)</li>
            <li>UUID shows poor thread scaling (throughput actually decreases)</li>
        </ul>
    </li>
    <li><strong>Consistency:</strong>
        <ul>
            <li>OpenTelemetry has very small error margins (±0.130 to ±1.525)</li>
            <li>UUID shows larger variations (±8.476 to ±65.991)</li>
        </ul>
    </li>
</ul>

<h2>Best Practices</h2>

<p>When writing JMH benchmarks, keep these points in mind:</p>

<ul>
    <li>Use <strong>Blackhole.consume()</strong> to prevent dead code elimination</li>
    <li>Include proper warmup iterations to ensure JVM optimization</li>
    <li>Run multiple forks to get statistically significant results</li>
    <li>Consider external factors like garbage collection and JIT compilation</li>
    <li>Document your benchmark environment (JVM version, available processors, etc.)</li>
</ul>

<h2>Conclusion</h2>

<p>
JMH is a powerful tool for measuring and comparing code performance on the JVM. While it requires careful setup and interpretation, it provides valuable insights into code performance characteristics. Remember that microbenchmarks should be one of many tools in your performance testing arsenal, alongside profiling and real-world performance testing.
</p>

<p>
The example used in this post can be found in the <a href="https://github.com/GSSwain/benchmark-trace-id-generator">benchmark-trace-id-generator</a> repository.
</p>]]></content><author><name>Girija Swain</name></author><summary type="html"><![CDATA[In the world of software development, performance matters. But how do we accurately measure and compare the performance of different implementations? This is where JMH (Java Microbenchmark Harness) comes into play. In this post, we'll explore JMH through a practical example of benchmarking trace ID generation methods.]]></summary></entry><entry><title type="html">Serverless PDF Generation from HTML (WYSIWYG as PDF)</title><link href="https://gsswain.com/2021/03/14/serverless-pdf-generation-from-html-wysiwyg-as-pdf.html" rel="alternate" type="text/html" title="Serverless PDF Generation from HTML (WYSIWYG as PDF)" /><published>2021-03-14T00:00:00+00:00</published><updated>2021-03-14T00:00:00+00:00</updated><id>https://gsswain.com/2021/03/14/serverless-pdf-generation-from-html-wysiwyg-as-pdf</id><content type="html" xml:base="https://gsswain.com/2021/03/14/serverless-pdf-generation-from-html-wysiwyg-as-pdf.html"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*feAZdBBLCdvr46oRhe8fVg.png" /></figure>
<p>In this post, we’ll learn how to create PDF document from HTML using Puppeteer. We’ll also look at a
    <em>Serverless</em> solution using AWS Lambda. This solution can run on most public clouds and on premises with
    minor or no modifications.
</p>
<h4>Prerequisite:</h4>
<p>You must be familiar with NodeJS &amp; ES6 to follow along the code examples.<br>You must be familiar with AWS Lambda
    &amp; AWS SAM to follow the <em>AWS</em> based <em>Serverless</em> example.</p>
<h3>How do you generate PDF?</h3>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Dk6SjE_rT-qzJA0--Y8Xjw.png" /></figure>
<p>Generally you have a template with placeholders. You need to replace the placeholders with actual data and generate a
    PDF using some compute. The text of the template may come from one team (product and/or legal team), while the look
    and feel of the template may come from another team (UX or CX team). From a developer’s perspective, he/she gets a
    sample PDF (with dummy data as placeholder) on some story on an agile board. Now the developer would reverse
    engineer this sample PDF and develop the code to generate similar PDFs with different sets of data.</p>
<p>Throughout my professional career, I have used multiple tools for generating PDFs including <em>OpenText
        StreamServe</em>, <em>iText</em>, <em>JasperReports</em>, <em>Apache PDFbox, Adobe Coldfusion and jsPDF.
    </em>Being a developer at heart, I certainly have my own bias towards which tool is best among them. In 2017, at
    GDDIndia I was introduced to Puppeteer.(I was there and it was all real. I badly miss being physically present on
    such events ever since Covid-19 has emerged.) Here is the Youtube video of the session.</p><iframe
    src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FXEw_n_wsk1o%3Fstart%3D639%26feature%3Doembed%26start%3D639%26end%3D1120&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DXEw_n_wsk1o&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FXEw_n_wsk1o%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube"
    width="854" height="480" frameborder="0" scrolling="no"><a
        href="https://medium.com/media/1ae7521bef933ebe99e57c9bb27ae001/href">https://medium.com/media/1ae7521bef933ebe99e57c9bb27ae001/href</a></iframe>
<p>With just a few lines of code, one can generate a PDF from a HTML page.<br>Is generating a PDF this simple? Yes,
    it is!</p>
<h3>Puppeteer:</h3>
<blockquote>Puppeteer is a Node library which provides a high-level API to control Chrome or Chromium over the <a
        href="https://chromedevtools.github.io/devtools-protocol/">DevTools Protocol</a>. By default, it launches in
    headless mode and can do everything a modern browser can, including rendering HTML with CSS. It is under <a
        href="https://github.com/puppeteer/puppeteer/blob/main/LICENSE">Apache License 2.0</a> and comes with permission
    for commercial use.</blockquote>
<h3>Show me the code</h3>
<p>Here is the code block, which generates a PDF given an URL and a name for the PDF file.</p>
<pre>const puppeteer = require(&#39;puppeteer&#39;);</pre>
<pre>const generatePDF = async (pageUrl, newPdfFileName) =&gt; {<br>   const browser = await puppeteer.launch();<br>   const page = await browser.newPage();<br>   await page.goto(pageUrl, {<br>      waitUntil: &#39;networkidle0&#39;<br>   });<br>   await page.pdf({<br>       path: `/tmp/${newPdfFileName}`,<br>       format: &#39;a4&#39;,<br>       printBackground: true<br>   });<br>   await browser.close();<br>}</pre>
<h3>What does the above code do?</h3>
<p>It uses Puppeteer to launch a browser. Then it opens a new page and navigates to a given URL and waits till the page
    is <em>fully loaded</em> (in the above code fully loaded means, Puppeteer would wait until no new network requests
    are sent for half a second after page load). Then it generates a PDF of the rendered page and finally closes
    the browser.</p>
<h4>Sample Usage:</h4>
<p>The following line of code would create a PDF version of a sample html page using the above function.</p>
<pre>generatePDF(‘https://gsswain.com/print-sample/&#39;, &#39;Print-sample.pdf&#39;);</pre>
<h3>Do I need to host the HTML pages publicly?</h3>
<p><strong>No.</strong><br>1. You need to ensure the above code (when running on some compute) should be able to access
    your html page. You can host the pages privately (on your intranet may be or have a private api which responds with
    html pages to be printed).<br>2. The browser can render local html files with
    <em>file:///&lt;path-to-your-html-page&gt; e.g.
        page.goto(‘</em>file:///Users/gsswain/Documents/gsswain.com/print-sample/index.html’<em>)<br>3. </em>You can
    directly render HTML by calling the<em> page.setContent(&lt;html-to-be-rendered&gt;) </em>method instead of
    calling<em> page.goto() </em>in the above code snippet<em>.</em>
</p>
<h3>How does this solution help?</h3>
<p>The UX/CX team can provide a HTML/CSS based templates rather than providing a sample PDF and you just need to focus
    on replacing the placeholders with actual data and the above function would take care of generating your PDF. If the
    UX/CX team provides a sample PDF, in that case you can either use some tool to convert the PDF into HTML and create
    a template out of that or you can use the expertise of your web developers to create the HTML and CSS based
    templates. Preferably convincing your UX/CX team to provide the HTML templates would be more efficient and make the
    entire process a lot faster.</p>
<p><strong><em>Side note:</em></strong> I personally like the JS template strings to create templates (instead of using
    another tool/framework/library) and some generic JS code which would take care of validation, replacing the place
    holders with real data and finally give me the HTML page to create a PDF. I would write more on this templating
    solution on a different post and would update the link here.</p>
<h3>Have you used this on production?</h3>
<p><em>Short answer-</em> <strong>YES.<br></strong><em>Long answer-</em> I always wanted to use this in production, but
    you know, it’s difficult to convince people 😜. What’s life without meetings!. <strong>This is tested on
        production</strong> and has done really well generating documents with 30–40 pages (most of the testing anyways
    happens on production only 😜). As promised I’ll give a AWS Lambda based Serverless solution.</p>
<h3>Generating PDF from HTML on AWS Lambda</h3>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ABfSa_ESG33cI6wPH4sdxg.png" /></figure>
<p>The above image shows all the AWS resources that we are going to create. I’ll briefly explain the solution below.</p>
<ul>
    <li>The Lambda sits behind API Gateway. The API accepts a request payload in JSON format. This payload must contain
        an url for which a PDF needs to be generated. The Lambda generates the required PDF and puts it in a S3 bucket.
        Finally the API responds with a 201 HTTP status code and a location header containing the S3 object URL. (For
        supporting CORS one needs to return the S3 URL in the response body as well.)</li>
    <li>For this example, the S3 bucket has a bucket policy which only allows <strong>public access to objects tagged
            with <em>public=yes.</em></strong>(You should <strong>ideally block public access to S3</strong> and either
        share a S3 Signed URL or a CloudFront Signed URL)</li>
    <li>We also have a Usage plan to restrict the maximum number of requests one can make and an API key is mandatory to
        access the API.</li>
    <li>The Puppeteer dependency is put into a Lambda Layer. Instead of using the <em>puppeteer</em> <em>npm</em>
        library we need to use <em>chrome-aws-lambda </em>as per the troubeleshooting guideline <a
            href="https://github.com/puppeteer/puppeteer/blob/main/docs/troubleshooting.md">here</a>.</li>
</ul>
<h3>Lambda Source Code</h3>
<p>Let’s see the AWS SAM template first</p>
<h4>SAM template (template.yaml)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=template.yaml"> </script>
<p><em>The </em>Lambda Runtime<em> is </em><em>NodeJS 14.x and the code is written in </em><em>ES6. With </em><em>Node
        14 Module support (specify </em><em>&quot;type&quot;: &quot;module&quot; in </em><em>package.json) I thought we
        might not have to transpile, but it does not work on </em><em>AWS Lambda yet. The Lambda runtime itself uses a
    </em><em>require(&lt;path-to-handler&gt; for the</em><em>handler configured in the </em><em>Lambda. So we need to
        transpile and I’m transpiling using </em><em>Babel</em>. Look at the package.json and the build.sh files below
    for the transpilation. Also note the Handler in the above template points to the dist directory.</p>
<p>Now let’s see the Lambda code.</p>
<h4>Lambda Handler (pdf-generator/src/app.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=app.js"> </script>
<p>The handler simply delegates to the PDF Generation Request handler.</p>
<h4>Pdf Generation Request Handler (pdf-generator/src/pdf-generation-request-handler.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=pdf-generation-request-handler.js"> </script>
<p>This request handler orchestrates the request. First it converts the Lambda event into a PDF Generation request in
    the constructor (You can take care of any validations here using ValueObject pattern). In the handleRequest method,
    it creates the PDF using the PDF Generation Service, stores it on S3using the S3 PDF Storage Service and finally
    sends the PDF created response.</p>
<h4>Pdf Generation Request Adapter (pdf-generator/src/pdf-generation-request-adapter.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=pdf-generation-request-adapter.js"> </script>
<p>Just picks up the url from the request body and generates a random file name for the PDF. (The name generation code
    can be place in another file or can also be taken as an input in the request payload).</p>
<h4>Pdf Generation Service (pdf-generator/src/pdf-generation-service.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=pdf-generation-service.js"> </script>
<p>This service expects the PDF Generation request. It generates the PDF file in the tmp folder and returns the path to
    the file from the generate method. Notice the difference in terms of the import of chromium and how we launch
    Puppeteer. There is also a DEFAULT_PRINT_OPTIONS which can be overridden by accepting the same in the request
    payload. For this example, the default should do.</p>
<h4>Pdf Storage Service (pdf-generator/src/s3-pdf-storage-service.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=s3-pdf-storage-service.js"> </script>
<p>This stores the file on S3 and <em>returns the HTTP based object URL</em>.</p>
<p><strong><em>Note:</em></strong> When running on local with sam local start-api, if we set the MODE to SAM_LOCAL, then
    it would not try to upload to S3, instead return a dummy URL.</p>
<h4>PDF Generation Request (pdf-generator/src/pdf-storage-request.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=pdf-storage-request.js"> </script>
<h4>S3 PDF Storage Request Adapter (pdf-generator/src/s3-pdf-storage-request-adapter.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=s3-pdf-storage-request-adapter.js"> </script>
<p>This takes care of creating a PutObjectCommand for storing the PDF. We are tagging the object with public=yes and the
    ContentDisposition is set to attachment which would start downloading the file on a browser.</p>
<h4>File Service (pdf-generator/src/file-service.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=file-service.js"> </script>
<p>This file returns a read stream for a file.</p>
<h4>Pdf Generation Response Adapter (pdf-generator/src/pdf-generation-response-adapter.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=pdf-generation-response-adapter.js"> </script>
<p>This converts the response as expected by AWS API Gateway.</p>
<h4>Config (pdf-generator/src/config.js)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=config.js"> </script>
<p>Use this Config file instead of reading the configuration from the environment variables directly everywhere in
    the code.</p>
<h4>package.json (pdf-generator/package.json)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=package.json"> </script>
<p><strong><em>Note: </em></strong>The transpile script uses Babel to transform the modules to CommonJS</p>
<h4>build.sh</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=build.sh"> </script>
<p>Takes care of transpiling the JS code before running sam build</p>
<h4>.npmignore</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=.npmignore"> </script>

<p>Ignore the tests and src files to be included in the lambda package.</p>
<h4>Lambda Layer package.json (dependencies/nodejs/node14/package.json)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=layer-package.json"> </script>
<p>This file contains all the dependencies which should go into the Lambda Layer. Also revisit the
    PuppeteerDependencyLayer in the above SAM template.</p>
<h4>main.yml(.github/workflows/main.yml)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=ci.yml"> </script>
<p>This section is optional and is not a requirement for building and deploying AWS Lambda. You can use your favourite
    CI/CD tool.<br>The above file is a Github Actions workflow configuration file. <strong>This will trigger the build,
        validate the SAM template and then deploy to AWS on git push</strong>. <strong><em>Now that’s real power and
            productivity ❤️</em></strong><em>. </em>You need to set the <strong><em>secrets</em></strong>
    (<em>AWS_ACCESS_KEY_ID</em>, <em>AWS_SECRET_ACCESS_KEY</em> and <em>AWS_DEFAULT_REGION</em>) in your Github repo for
    this to work.</p>
<p><em>I humbly thank the </em><em>Github team and </em><em>Microsoft for Github Actions.</em></p>
<h4>Parameters for sam local (sam-local-env.json)</h4>
<script src="https://gist.github.com/cc133627507af9e4454308a4c8e68bf6.js?file=sam-local-env.json"> </script>
<p>The above file contains the parameter overrides for testing the Lambda on local. One can also use LocalStack for a
    complete integration test (a topic which would need a separate post).</p>
<p>Now that’s all the code. The entire repo is available <a
        href="https://github.com/Girija-Shankar-Swain/html-to-pdf-generator-puppeteer-aws-lambda">here</a> for
    reference. Feel free to send a pull request, if you have any suggestions.</p>
<h3>Build on Local:</h3>
<p>Run the build.sh script to build the project on local.</p>
<h3>Test on Local:</h3>
<p>Make sure you have Docker installed and running on your machine.</p>
<h4>Start the api</h4>
<p>sam local start-api --env-vars sam-local-env.json</p>
<p>Now you can test the API deployed on local, with the following request.</p>
<h4>Sample Request:</h4>
<pre>curl -i -X POST \<br>  <a href="http://127.0.0.1:3000/generate-pdf/">http://127.0.0.1:3000/generate-pdf/</a> \<br>  -H &#39;cache-control: no-cache&#39; \<br>  -H &#39;content-type: application/json&#39; \<br>  -d &#39;{<br> &quot;url&quot;: &quot;<a href="https://gsswain.com/print-sample/">https://gsswain.com/print-sample/</a>&quot;<br>}&#39;</pre>
<h4>Sample Response:</h4>
<pre>HTTP/1.0 201 CREATED<br>Content-Type: application/json<br>Access-Control-Allow-Origin: <a href="http://localhost:8080">http://localhost:8080</a><br>location: <a href="https://dummyS3Url/3c8e8e4c-f7b4-4f5b-8e85-8dc06f8a22c3_1615739992609_353075938260911200.pdf">https://dummyS3Url/3c8e8e4c-f7b4-4f5b-8e85-8dc06f8a22c3_1615739992609_353075938260911200.pdf</a><br>Content-Length: 105<br>Server: Werkzeug/1.0.1 Python/3.8.8<br>Date: Sun, 14 Mar 2021 16:39:57 GMT</pre>
<pre>{&quot;pdfUrl&quot;:&quot;https://dummyS3Url/3c8e8e4c-f7b4-4f5b-8e85-8dc06f8a22c3_1615739992609_353075938260911200.pdf&quot;}</pre>
<h3>Deploy on AWS:</h3>
<p>You can use sam deploy --guided to deploy the Lambda.<br>If you use Github as your repo, then you can build and
    deploy using Github Actions which was covered above.<br>For the CI/CD deploy to work, you need to have the
    samconfig.toml file with appropriate values. Refer to the one in my <a
        href="https://github.com/GSSwain/html-to-pdf-generator-puppeteer-aws-lambda">repo</a>.</p>
<h3>Test the deployed solution</h3>
<p>If you have deployed this to your AWS account, you must pass the api key in the headers. You need to go the AWS
    CloudFormation stack and then to the resources. Go to the ApiKey resource and then click show.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*bLWB5IFXIPj74mbE0fXAuA.png" /></figure>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*r5AnkOsy6ODVzjAWxciC6Q.png" /></figure>
<p>You can get the URL of the API in the Output section of the AWS CloudFormation Stack.</p>
<p>Now you can test the API deployed on AWS with the following request.</p>
<h4>Sample Request:</h4>
<pre>curl -i -X POST \<br>  <a href="https://lote3qjqz8.execute-api.ap-southeast-2.amazonaws.com/Prod/generate-pdf/">https://&lt;YOUR-API-ID&gt;.execute-api.ap-southeast-2.amazonaws.com/Prod/generate-pdf/</a> \<br>  -H &#39;cache-control: no-cache&#39; \<br>  -H &#39;content-type: application/json&#39; \<br>  -H &#39;x-api-key: &lt;YOUR-API-KEY_GOES_HERE&gt;&#39; \<br>  -d &#39;{<br> &quot;url&quot;: &quot;<a href="https://gsswain.com/print-sample/">https://gsswain.com/print-sample/</a>&quot;<br>}&#39;</pre>
<h4>Sample Response:</h4>
<pre>HTTP/2 201<br>content-type: application/json<br>content-length: 171<br>location: &lt;GENERATED_PDF_URL&gt;<br>date: Sun, 14 Mar 2021 15:26:36 GMT<br>x-amzn-requestid: 8aa9cd12-aaa9-4628-96db-e2d7b952feb5<br>access-control-allow-origin: <a href="https://gsswain.com">https://gsswain.com</a><br>x-amz-apigw-id: cLuuTFlYSwMF5dw=<br>x-amzn-trace-id: Root=1-604e2b28-1cff94e27f34e4e35ec1a6e8;Sampled=0<br></pre>
<pre>{&quot;pdfUrl&quot;:&quot;&lt;GENERATED_PDF_URL&gt;&quot;}</pre>
<p>Copy the pdfUrl value returned in the response and open in a browser and you should see the PDF version of the page.
    Check the tags and metadata in the S3 bucket.</p>
<p><strong><em>Note:</em></strong> You can’t access all the objects in the bucket unless you know the bucket key for all
    of them. Also if you upload directly to S3 without the tag public=yes, they can’t be accessed even if you know the
    bucket key. With that we have covered a lot of ground and finally tested our lambda on AWS as well.</p>
<h3>Cleanup:</h3>
<p>After you have done your testing delete all the resources</p>
<h4>Delete all objects in S3 bucket</h4>
<p>aws s3 rm s3://&lt;your-s3-bucket-name&gt; --recursive</p>
<h4>Delete the CloudFormation Stack</h4>
<p>aws cloudformation delete-stack --stack-name &lt;name-of-your-cfn-stack&gt;</p>
<h3>Summary:</h3>
<p>I hope you learnt a little something and you can use this solution somewhere on production 😊. This is half the
    story. Ideally you would like to have an API which would take a templateId, <strong><em>some data for the template
        </em></strong>and generate a PDF with that. This code example generates a PDF, given a URL. You can easily build
    upon this to support templates. If you are having any issues with Puppeteer<em> </em>while<em> </em>deploying this
    solution to some other platform, please go through the troubleshooting guide <a
        href="https://github.com/puppeteer/puppeteer/blob/main/docs/troubleshooting.md">here</a>.</p>
<p><strong><em>Note:</em> </strong>There is at least two sides to everything.<strong> </strong>Lambda <strong>is not a
        silver bullet</strong> and you should have some expert opinion before using them for your use case. This
    solution would work best when your target is high throughput rather than low latency. I have intentionally kept the
    ReserverConcurrentExecutions to 1 in the SAM template. Play around the <em>Memory, Concurrency</em> mode for your
    use case. If you need help do reach out to me.</p>
<h3>References:</h3>
<ul>
    <li><a href="https://developers.google.com/web/tools/puppeteer">Puppeteer</a></li>
    <li><a href="https://nodejs.org/en/blog/release/v14.0.0/">NodeJS 14</a></li>
    <li><a href="https://aws.amazon.com/lambda/">AWS Lambda</a></li>
    <li><a href="https://aws.amazon.com/serverless/sam/">AWS SAM</a></li>
    <li><a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html">AWS Lambda Layer</a></li>
    <li><a href="https://aws.amazon.com/blogs/compute/working-with-aws-lambda-and-lambda-layers-in-aws-sam/">AWS Lambda
            Layer with SAM</a></li>
    <li><a href="https://aws.amazon.com/cli/">AWS CLI</a></li>
    <li><a href="https://docs.github.com/en/actions">Github Actions</a></li>
    <li><a href="https://babeljs.io/docs/en/">Babel</a></li>
    <li><a href="https://localstack.cloud/#intro">LocalStack</a></li>
</ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2f295a23cb6d" width="1"
    height="1" alt="">]]></content><author><name>Girija Swain</name></author><category term="aws-lambda" /><category term="aws-sam" /><category term="puppeteer" /><category term="pdf-generation" /><category term="serverless" /><summary type="html"><![CDATA[In this post, we’ll learn how to create PDF document from HTML using Puppeteer. We’ll also look at a Serverless solution using AWS Lambda. This solution can run on most public clouds and on premises with minor or no modifications. Prerequisite: You must be familiar with NodeJS &amp; ES6 to follow along the code examples.You must be familiar with AWS Lambda &amp; AWS SAM to follow the AWS based Serverless example. How do you generate PDF? Generally you have a template with placeholders. You need to replace the placeholders with actual data and generate a PDF using some compute. The text of the template may come from one team (product and/or legal team), while the look and feel of the template may come from another team (UX or CX team). From a developer’s perspective, he/she gets a sample PDF (with dummy data as placeholder) on some story on an agile board. Now the developer would reverse engineer this sample PDF and develop the code to generate similar PDFs with different sets of data. Throughout my professional career, I have used multiple tools for generating PDFs including OpenText StreamServe, iText, JasperReports, Apache PDFbox, Adobe Coldfusion and jsPDF. Being a developer at heart, I certainly have my own bias towards which tool is best among them. In 2017, at GDDIndia I was introduced to Puppeteer.(I was there and it was all real. I badly miss being physically present on such events ever since Covid-19 has emerged.) Here is the Youtube video of the session.https://medium.com/media/1ae7521bef933ebe99e57c9bb27ae001/href With just a few lines of code, one can generate a PDF from a HTML page.Is generating a PDF this simple? Yes, it is! Puppeteer: Puppeteer is a Node library which provides a high-level API to control Chrome or Chromium over the DevTools Protocol. By default, it launches in headless mode and can do everything a modern browser can, including rendering HTML with CSS. It is under Apache License 2.0 and comes with permission for commercial use. Show me the code Here is the code block, which generates a PDF given an URL and a name for the PDF file. const puppeteer = require(&#39;puppeteer&#39;); const generatePDF = async (pageUrl, newPdfFileName) =&gt; { const browser = await puppeteer.launch(); const page = await browser.newPage(); await page.goto(pageUrl, { waitUntil: &#39;networkidle0&#39; }); await page.pdf({ path: `/tmp/${newPdfFileName}`, format: &#39;a4&#39;, printBackground: true }); await browser.close();} What does the above code do? It uses Puppeteer to launch a browser. Then it opens a new page and navigates to a given URL and waits till the page is fully loaded (in the above code fully loaded means, Puppeteer would wait until no new network requests are sent for half a second after page load). Then it generates a PDF of the rendered page and finally closes the browser. Sample Usage: The following line of code would create a PDF version of a sample html page using the above function. generatePDF(‘https://gsswain.com/print-sample/&#39;, &#39;Print-sample.pdf&#39;); Do I need to host the HTML pages publicly? No.1. You need to ensure the above code (when running on some compute) should be able to access your html page. You can host the pages privately (on your intranet may be or have a private api which responds with html pages to be printed).2. The browser can render local html files with file:///&lt;path-to-your-html-page&gt; e.g. page.goto(‘file:///Users/gsswain/Documents/gsswain.com/print-sample/index.html’)3. You can directly render HTML by calling the page.setContent(&lt;html-to-be-rendered&gt;) method instead of calling page.goto() in the above code snippet. How does this solution help? The UX/CX team can provide a HTML/CSS based templates rather than providing a sample PDF and you just need to focus on replacing the placeholders with actual data and the above function would take care of generating your PDF. If the UX/CX team provides a sample PDF, in that case you can either use some tool to convert the PDF into HTML and create a template out of that or you can use the expertise of your web developers to create the HTML and CSS based templates. Preferably convincing your UX/CX team to provide the HTML templates would be more efficient and make the entire process a lot faster. Side note: I personally like the JS template strings to create templates (instead of using another tool/framework/library) and some generic JS code which would take care of validation, replacing the place holders with real data and finally give me the HTML page to create a PDF. I would write more on this templating solution on a different post and would update the link here. Have you used this on production? Short answer- YES.Long answer- I always wanted to use this in production, but you know, it’s difficult to convince people 😜. What’s life without meetings!. This is tested on production and has done really well generating documents with 30–40 pages (most of the testing anyways happens on production only 😜). As promised I’ll give a AWS Lambda based Serverless solution. Generating PDF from HTML on AWS Lambda The above image shows all the AWS resources that we are going to create. I’ll briefly explain the solution below. The Lambda sits behind API Gateway. The API accepts a request payload in JSON format. This payload must contain an url for which a PDF needs to be generated. The Lambda generates the required PDF and puts it in a S3 bucket. Finally the API responds with a 201 HTTP status code and a location header containing the S3 object URL. (For supporting CORS one needs to return the S3 URL in the response body as well.) For this example, the S3 bucket has a bucket policy which only allows public access to objects tagged with public=yes.(You should ideally block public access to S3 and either share a S3 Signed URL or a CloudFront Signed URL) We also have a Usage plan to restrict the maximum number of requests one can make and an API key is mandatory to access the API. The Puppeteer dependency is put into a Lambda Layer. Instead of using the puppeteer npm library we need to use chrome-aws-lambda as per the troubeleshooting guideline here. Lambda Source Code Let’s see the AWS SAM template first SAM template (template.yaml) The Lambda Runtime is NodeJS 14.x and the code is written in ES6. With Node 14 Module support (specify &quot;type&quot;: &quot;module&quot; in package.json) I thought we might not have to transpile, but it does not work on AWS Lambda yet. The Lambda runtime itself uses a require(&lt;path-to-handler&gt; for thehandler configured in the Lambda. So we need to transpile and I’m transpiling using Babel. Look at the package.json and the build.sh files below for the transpilation. Also note the Handler in the above template points to the dist directory. Now let’s see the Lambda code. Lambda Handler (pdf-generator/src/app.js) The handler simply delegates to the PDF Generation Request handler. Pdf Generation Request Handler (pdf-generator/src/pdf-generation-request-handler.js) This request handler orchestrates the request. First it converts the Lambda event into a PDF Generation request in the constructor (You can take care of any validations here using ValueObject pattern). In the handleRequest method, it creates the PDF using the PDF Generation Service, stores it on S3using the S3 PDF Storage Service and finally sends the PDF created response. Pdf Generation Request Adapter (pdf-generator/src/pdf-generation-request-adapter.js) Just picks up the url from the request body and generates a random file name for the PDF. (The name generation code can be place in another file or can also be taken as an input in the request payload). Pdf Generation Service (pdf-generator/src/pdf-generation-service.js) This service expects the PDF Generation request. It generates the PDF file in the tmp folder and returns the path to the file from the generate method. Notice the difference in terms of the import of chromium and how we launch Puppeteer. There is also a DEFAULT_PRINT_OPTIONS which can be overridden by accepting the same in the request payload. For this example, the default should do. Pdf Storage Service (pdf-generator/src/s3-pdf-storage-service.js) This stores the file on S3 and returns the HTTP based object URL. Note: When running on local with sam local start-api, if we set the MODE to SAM_LOCAL, then it would not try to upload to S3, instead return a dummy URL. PDF Generation Request (pdf-generator/src/pdf-storage-request.js) S3 PDF Storage Request Adapter (pdf-generator/src/s3-pdf-storage-request-adapter.js) This takes care of creating a PutObjectCommand for storing the PDF. We are tagging the object with public=yes and the ContentDisposition is set to attachment which would start downloading the file on a browser. File Service (pdf-generator/src/file-service.js) This file returns a read stream for a file. Pdf Generation Response Adapter (pdf-generator/src/pdf-generation-response-adapter.js) This converts the response as expected by AWS API Gateway. Config (pdf-generator/src/config.js) Use this Config file instead of reading the configuration from the environment variables directly everywhere in the code. package.json (pdf-generator/package.json) Note: The transpile script uses Babel to transform the modules to CommonJS build.sh Takes care of transpiling the JS code before running sam build .npmignore]]></summary></entry><entry><title type="html">Quarkus and the Java Developer Experience</title><link href="https://gsswain.com/2020/09/20/quarkus-and-the-java-developer-experience.html" rel="alternate" type="text/html" title="Quarkus and the Java Developer Experience" /><published>2020-09-20T00:00:00+00:00</published><updated>2020-09-20T00:00:00+00:00</updated><id>https://gsswain.com/2020/09/20/quarkus-and-the-java-developer-experience</id><content type="html" xml:base="https://gsswain.com/2020/09/20/quarkus-and-the-java-developer-experience.html"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*4Oxs97dZeDJuT4UnvIAc9g.jpeg" /></figure><p>This post covers </p><ul><li>What is Quarkus? </li><li>Getting started with Quarkus. </li><li>What is native executable? </li><li>Building <em>native executable from Java using Quarkus</em>. </li><li>Startup time difference for Jar and native executables. </li><li><em>Hot code replacement</em> for Java (For me this is one of the biggest USP of the framework). </li></ul><h3>What is Quarkus?</h3><blockquote>Quarkus is a full-stack, Kubernetes-native <a href="https://www.redhat.com/en/topics/cloud-native-apps/what-is-a-Java-framework">Java framework</a> made for Java virtual machines (JVMs) and native compilation, optimizing Java specifically for containers and enabling it to become an effective platform for <a href="https://www.redhat.com/en/topics/cloud-native-apps/what-is-serverless">serverless</a>, <a href="https://www.redhat.com/en/topics/cloud">cloud</a>, and <a href="https://www.redhat.com/en/topics/containers/what-is-kubernetes">Kubernetes</a> environments.</blockquote><h3>Getting started with Quarkus</h3><p>You would need to have Java 8 or Java 11 installed along with Maven to get started with Quarkus.</p><h4>Create a Boilerplate REST project</h4><p>Let’s use the Maven plugin to create a boilerplate</p><pre>mvn io.quarkus:quarkus-maven-plugin:1.8.1.Final:create</pre><p>Now it would ask for the <em>groupId, artifcatId, version </em>to be entered. It would also ask if we want a REST resource (say yes) followed by the <em>classname</em> and the <em>path</em> of the rest resource. This is how it would look like</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1016/1*Ynag2d-Mio8ptTapuA2MHQ.png" /></figure><p>Now we have a Quarkus boilerplate project ready to be build and run.</p><h4>Build the project</h4><p>To create a Jar run the following command.</p><p>mvn package</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/1*E0Wnq1tElKnKdakJCK6aaQ.jpeg" /></figure><p>The build took around <strong>16 seconds</strong>.</p><p>We cover building <em>native executable</em> in the next section.</p><h4>Run the project</h4><p>java -jar target/quarkus-hello-world-1.0-SNAPSHOT-runner.jar</p><h4>Test the project</h4><p>Either use curl or open it on a browser and check</p><p>curl <a href="http://localhost:8080/hello">http://localhost:8080/hello</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/904/1*vB8gHFcpTJ3Uahle9dzxgQ.png" /></figure><h3>What is native executable?</h3><p>In the world of Java, we compile the source code to Java byte code (Job of <em>javac</em>). When we run this compiled code, the Java byte code is converted to machine specific code (<em>JRE</em> does this). What if we could compile the Java source code to machine specific code and run the machine code directly without a JRE. This is exactly what a native executable is and <strong><em>GraalVM</em></strong> <em>native-image</em> can do this for us.</p><blockquote>With native executables, we don’t need the JRE to run java code anymore . Those native executables are <strong>faster to bootstrap</strong> and <strong>need less resources to run</strong>. The only thing we need to give up is the <strong>Write</strong> <strong>Once Run Anywhere (WORA)</strong>. That means the code would only run on similar systems on which it was compiled. But wait! Can’t we build for a specific machine and run the code along with that machine? Yes, we could do this with a <strong>container-image</strong>. So we still get WORA as long as the <strong>container run time can run on any machine</strong>.</blockquote><h3>Building native executable from Java using Quarkus</h3><p>With Quarkus we can build the following native executables</p><ol><li>Native executable for our development machine (Won’t run on different OS or even with same OS)</li><li>Container image with native executable (Runs everywhere where the container runtime is supported)</li></ol><h3>1. Build native executable for our development machine</h3><p>Following are the steps to create a native executable for your development machine.</p><ul><li><a href="https://www.graalvm.org/docs/getting-started-with-graalvm/#install-graalvm">Install GraalVM</a></li><li>Set <em>GRAALVM_HOME </em>environment variable</li><li>Add <em>GRAALVM_HOME/bin </em>directory to<em> PATH</em></li><li>Install GraalVM <em>native-image</em> utility (Run gu install native-image)</li><li>Set up <em>C </em>Langauge environment (Varies for different OS and covered below)</li><li>Finally run maven package with the native profile enabled (On Windows an extra step is required and covered below)</li></ul><h4>Setting up C</h4><p>On a Mac run the following command</p><pre>xcode-select --install</pre><p>On a Linux based system run the following command</p><pre># dnf (rpm-based)<br>sudo dnf install gcc glibc-devel zlib-devel libstdc++-static<br># Debian-based distributions:<br>sudo apt-get install build-essential libz-dev zlib1g-dev</pre><p>On Windows 10, get the <em>Visual Studio 2019 C++ build tools</em> and install the checked optional packages (I have used the community edition)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*4_v2StXKD9p7G7k6wZhBsQ.jpeg" /></figure><h4>Build native executable</h4><p>For building the native image, we need to run the following command</p><p>mvn package -Pnative</p><p>For Windows 10, you <strong>must be using the command prompt</strong> (does not work on PowerShell yet). You need to run the following batch file before running the native maven build (The path to this file would vary depending upon the version of Visual Studio e.g. 2019, 2017 and if it Community or not)</p><pre>&quot;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat&quot;</pre><p>I have created a cmd file (native-build-windows.cmd) which runs both the commands for me.</p><pre>call &quot;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat&quot;</pre><pre>mvn package -Pnative</pre><p>Once you run this, you would get a native executable</p><p>On Mac, it creates an executable file named quarkus-hello-world-1.0-SNAPSHOT-runner under the target directory.</p><p>On Windows-10 an <em>exe </em>named<em> </em>quarkus-hello-world-1.0-SNAPSHOT-runner.exe is created under the target diectory.</p><p>Run this file and do a round of testing. Note this executable will not run on different OS and may not run on different machines with same OS as well. So we need to create a container image which would run irrespective of the OS.</p><h3>2. Building container image with native executable</h3><p>Let’s start Docker and get going. (Allow file sharing on Docker)</p><p>Run the following command</p><p>mvn package -Pnative -Dquarkus.native.container-build=true</p><p>It would again build an executable but this time if you run it on your own machine, it would fail as the container build happens on the ubi-quarkus-native-image:20.2.0-java11 container.</p><p>To run the executable, we can create a container image and run that with the following command</p><pre># Build the image<br>docker build -f src/main/docker/Dockerfile.native -t quarkus/quarkus-hello-world .</pre><pre># Run the image<br>docker run -i --rm -p 8080:8080 quarkus/quarkus-hello-world</pre><p>This brings ubi8/ubi-minimal:8.1 image as the runtime for the executable.</p><p>There is an easier way to create the container image. Just add the following Quarkus extension using the below command</p><p>mvn quarkus:add-extension -Dextensions=quarkus-container-image-jib</p><p>Run the following command to build the Docker image</p><pre>mvn package -Pnative -Dquarkus.native.container-build=true -Dquarkus.container-image.build=true</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*LFAA1qIqyN2osZoGSSCz3g.jpeg" /></figure><p>The build took around <strong>8 minutes</strong>.</p><p>By default the container image group is your user-name of the PC. You can change it with setting a different value for quarkus.container-image.group in the application.properties file</p><p>Now run the docker image (Replace the container-image-group value)</p><p>docker run -I --rm -p 8080:8080 &lt;container-image-group&gt;/quarkus-hello-world:1.0-SNAPSHOT</p><h3>Startup time difference for Jar and native executables</h3><p>Here is a quick summary of the startup time for the various kinds of builds and runtime on a Windows 10 with 20GB of RAM with intel i5 processor.</p><p>The <strong>jar</strong> version took around<strong> 1.773 seconds</strong>, the <strong>native machine executable</strong> started in <strong>0.281 seconds</strong> and the <strong>native container image</strong> started in <strong>0.017 seconds</strong> 😊.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GEywE23svFHY4miD8gxgXw.jpeg" /></figure><h3>Hot code replacement for Java</h3><p>Hot code replacement is the idea, where we replace code which is already running. This was always there, <a href="https://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html#using-boot-devtools">SpringBoot Dev-tools</a> does this when the <em>classpath</em> gets updated. The hot code replacement with Quarkus is cool and very similar in experience to the NodeJS based eco-system (with a watch option on source files). It detects the changes on the source files, compiles them and replaces them.</p><p>Let’s see this in action</p><p>Start the project in dev mode</p><pre>mvnw quarkus:dev</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PwpeEFL-tvSlsne5sx2Wbg.jpeg" /></figure><p>Now let’s return “<em>hi” </em>instead of <em>“hello” </em>(any change would do) and save the file. You would notice the source file change would be detected and it would hot replace the code.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ZlLQK8WzoOJurGzC55xa7g.jpeg" /></figure><p>This certainly saves a few seconds to minutes (depending on your machine 😜). ❤️ this feature.</p><h3>Conclusion:</h3><p>Quarkus looks really good. I like the way it has given the much needed boost to the Java Developer experience and make us feel more productive. The supported eco-system is also promising (See it for yourself with mvn quarkus:list-extensions). I hope you would give it a try and discover for yourself.</p><h3>References:</h3><ul><li><a href="https://quarkus.io">Quarkus</a></li><li><a href="https://www.graalvm.org/why-graalvm/">GraalVM</a></li><li><a href="https://www.docker.com">Docker</a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b9817fe4e3d7" width="1" height="1" alt=""><hr><p><a href="https://medium.com/swlh/quarkus-and-the-java-developer-experience-b9817fe4e3d7">Quarkus and the Java Developer Experience</a> was originally published in <a href="https://medium.com/swlh">The Startup</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content><author><name>Girija Swain</name></author><category term="containers" /><category term="java" /><category term="graalvm" /><category term="developer-experience" /><category term="quarkus" /><summary type="html"><![CDATA[This post covers What is Quarkus? Getting started with Quarkus. What is native executable? Building native executable from Java using Quarkus. Startup time difference for Jar and native executables. Hot code replacement for Java (For me this is one of the biggest USP of the framework). What is Quarkus?Quarkus is a full-stack, Kubernetes-native Java framework made for Java virtual machines (JVMs) and native compilation, optimizing Java specifically for containers and enabling it to become an effective platform for serverless, cloud, and Kubernetes environments.Getting started with QuarkusYou would need to have Java 8 or Java 11 installed along with Maven to get started with Quarkus.Create a Boilerplate REST projectLet’s use the Maven plugin to create a boilerplatemvn io.quarkus:quarkus-maven-plugin:1.8.1.Final:createNow it would ask for the groupId, artifcatId, version to be entered. It would also ask if we want a REST resource (say yes) followed by the classname and the path of the rest resource. This is how it would look likeNow we have a Quarkus boilerplate project ready to be build and run.Build the projectTo create a Jar run the following command.mvn packageThe build took around 16 seconds.We cover building native executable in the next section.Run the projectjava -jar target/quarkus-hello-world-1.0-SNAPSHOT-runner.jarTest the projectEither use curl or open it on a browser and checkcurl http://localhost:8080/helloWhat is native executable?In the world of Java, we compile the source code to Java byte code (Job of javac). When we run this compiled code, the Java byte code is converted to machine specific code (JRE does this). What if we could compile the Java source code to machine specific code and run the machine code directly without a JRE. This is exactly what a native executable is and GraalVM native-image can do this for us.With native executables, we don’t need the JRE to run java code anymore . Those native executables are faster to bootstrap and need less resources to run. The only thing we need to give up is the Write Once Run Anywhere (WORA). That means the code would only run on similar systems on which it was compiled. But wait! Can’t we build for a specific machine and run the code along with that machine? Yes, we could do this with a container-image. So we still get WORA as long as the container run time can run on any machine.Building native executable from Java using QuarkusWith Quarkus we can build the following native executablesNative executable for our development machine (Won’t run on different OS or even with same OS)Container image with native executable (Runs everywhere where the container runtime is supported)1. Build native executable for our development machineFollowing are the steps to create a native executable for your development machine.Install GraalVMSet GRAALVM_HOME environment variableAdd GRAALVM_HOME/bin directory to PATHInstall GraalVM native-image utility (Run gu install native-image)Set up C Langauge environment (Varies for different OS and covered below)Finally run maven package with the native profile enabled (On Windows an extra step is required and covered below)Setting up COn a Mac run the following commandxcode-select --installOn a Linux based system run the following command# dnf (rpm-based)sudo dnf install gcc glibc-devel zlib-devel libstdc++-static# Debian-based distributions:sudo apt-get install build-essential libz-dev zlib1g-devOn Windows 10, get the Visual Studio 2019 C++ build tools and install the checked optional packages (I have used the community edition)Build native executableFor building the native image, we need to run the following commandmvn package -PnativeFor Windows 10, you must be using the command prompt (does not work on PowerShell yet). You need to run the following batch file before running the native maven build (The path to this file would vary depending upon the version of Visual Studio e.g. 2019, 2017 and if it Community or not)&quot;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat&quot;I have created a cmd file (native-build-windows.cmd) which runs both the commands for me.call &quot;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat&quot;mvn package -PnativeOnce you run this, you would get a native executableOn Mac, it creates an executable file named quarkus-hello-world-1.0-SNAPSHOT-runner under the target directory.On Windows-10 an exe named quarkus-hello-world-1.0-SNAPSHOT-runner.exe is created under the target diectory.Run this file and do a round of testing. Note this executable will not run on different OS and may not run on different machines with same OS as well. So we need to create a container image which would run irrespective of the OS.2. Building container image with native executableLet’s start Docker and get going. (Allow file sharing on Docker)Run the following commandmvn package -Pnative -Dquarkus.native.container-build=trueIt would again build an executable but this time if you run it on your own machine, it would fail as the container build happens on the ubi-quarkus-native-image:20.2.0-java11 container.To run the executable, we can create a container image and run that with the following command# Build the imagedocker build -f src/main/docker/Dockerfile.native -t quarkus/quarkus-hello-world .# Run the imagedocker run -i --rm -p 8080:8080 quarkus/quarkus-hello-worldThis brings ubi8/ubi-minimal:8.1 image as the runtime for the executable.There is an easier way to create the container image. Just add the following Quarkus extension using the below commandmvn quarkus:add-extension -Dextensions=quarkus-container-image-jibRun the following command to build the Docker imagemvn package -Pnative -Dquarkus.native.container-build=true -Dquarkus.container-image.build=trueThe build took around 8 minutes.By default the container image group is your user-name of the PC. You can change it with setting a different value for quarkus.container-image.group in the application.properties fileNow run the docker image (Replace the container-image-group value)docker run -I --rm -p 8080:8080 &lt;container-image-group&gt;/quarkus-hello-world:1.0-SNAPSHOTStartup time difference for Jar and native executablesHere is a quick summary of the startup time for the various kinds of builds and runtime on a Windows 10 with 20GB of RAM with intel i5 processor.The jar version took around 1.773 seconds, the native machine executable started in 0.281 seconds and the native container image started in 0.017 seconds 😊.Hot code replacement for JavaHot code replacement is the idea, where we replace code which is already running. This was always there, SpringBoot Dev-tools does this when the classpath gets updated. The hot code replacement with Quarkus is cool and very similar in experience to the NodeJS based eco-system (with a watch option on source files). It detects the changes on the source files, compiles them and replaces them.Let’s see this in actionStart the project in dev modemvnw quarkus:devNow let’s return “hi” instead of “hello” (any change would do) and save the file. You would notice the source file change would be detected and it would hot replace the code.This certainly saves a few seconds to minutes (depending on your machine 😜). ❤️ this feature.Conclusion:Quarkus looks really good. I like the way it has given the much needed boost to the Java Developer experience and make us feel more productive. The supported eco-system is also promising (See it for yourself with mvn quarkus:list-extensions). I hope you would give it a try and discover for yourself.References:QuarkusGraalVMDockerQuarkus and the Java Developer Experience was originally published in The Startup on Medium, where people are continuing the conversation by highlighting and responding to this story.]]></summary></entry><entry><title type="html">REST + GraphQL (beyond BFFs)</title><link href="https://gsswain.com/2020/07/28/rest-graphql-beyond-bffs.html" rel="alternate" type="text/html" title="REST + GraphQL (beyond BFFs)" /><published>2020-07-28T00:00:00+00:00</published><updated>2020-07-28T00:00:00+00:00</updated><id>https://gsswain.com/2020/07/28/rest-graphql-beyond-bffs</id><content type="html" xml:base="https://gsswain.com/2020/07/28/rest-graphql-beyond-bffs.html"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*OTe9AFXves6mRZIroTpdCQ.png" /></figure><p>In this post, we start with a brief introduction to GraphQL and its common industry accepted usage pattern as BFFs(Backends For Frontends). Can it be used beyond that? I would focus around the below questions</p><ul><li>What is GraphQL?</li><li>Do I need to use GraphQL?</li><li>Can GraphQL be used beyond Backends For Frontends(BFFs)?</li></ul><p><em>Basic knowledge of REST is a prerequisite for understanding the concepts in this post.</em></p><h3>What is GraphQL?</h3><p>GraphQL is a <strong>query language for APIs</strong> and a <strong>runtime for fulfilling those queries with your existing data</strong>. So there are 2 components to this. A <strong>GraphQL server</strong> and a <strong>GraphQL client</strong>. Both of them talk to each other using GrpahQL query language. GraphQL is transport agnostic and works well <strong>over HTTP</strong>. The client sends a GraphQL query, the server understands what the client has asked it to do and process the request and sends the response. In the REST world, we all know what <strong>CRUD </strong>(Create, Read, Update, Delete) stands for and how it works. In the GraphQL world, the <strong>reads are Queries</strong> and the <strong>writes are Mutations</strong>. That&#39;s it 😊</p><h4>History:</h4><p><strong>Facebook</strong>’s mobile apps have been powered by <strong>GraphQL</strong> <strong>since 2012</strong>. A <strong>GraphQL spec was</strong> <strong>open sourced in 2015</strong>.</p><h4>Schema:</h4><p>GraphQL has a <strong>Schema, </strong>which consists of <strong>Query</strong> (for read operations) and <strong>Mutation </strong>(for write operations) with it’s own type definitions.</p><pre>schema {<br>  query: Query<br>  mutation: Mutation<br>}</pre><h4>Query:</h4><p>Queries are used for read operations. Let’ take a simple example in the context of Facebook. A facebook user can log in and see multiple posts from their friends with a certain number of comments. An illustrative GraphQL type definition in this case may look something like this</p><pre>type <strong>Query</strong> {<br>  posts: [<strong>Post</strong>]         # This query fetches <strong>list of Post</strong>s<br>  ...                   # Other query definitions<br>}</pre><pre>type <strong>Post</strong> {<br>  id: ID!               # Id of the post<br>  at: String!           # Time at which it was Posted<br>  caption: String!      # Caption of the post<br>  mediaUrl: String      # Url to the image or video shared<br>  location: String      # Location of the post<br>  comments: [<strong>Comment</strong>]   # Comments on the post of type Comment<br>  ...                   # Other properties definition of a post<br>}</pre><pre>type <strong>Comment</strong> { <br>  id: ID!               # Id of the comment<br>  comment: String!      # The text of the comment<br>  at: String!           # Time at which it was Commented<br>  by: String!           # The user who made the comment<br>  ...                   # Other properties definition of a Comment</pre><pre>}    </pre><h4>Sample GraphQL Query:</h4><p>A sample query to fetch posts with comments for each post would look like the following</p><pre>query {<br>  posts {<br>    id<br>    at<br>    caption<br>    mediaUrl<br>    location<br>    comments {<br>      id<br>      comment<br>      at<br>      by<br>    } <br>  }<br>}</pre><p>If you look at the above query, we only ask for the <strong>required fields and nothing more </strong>for the posts as well as the comments for each post. There could be more fields both for posts and comments, which we don&#39;t need and they are not part of the response as well.</p><h4>Sample GraphQL Response</h4><p>Here is a sample response for the above mentioned query. Notice the top level key is &quot;<strong><em>data</em></strong>&quot; followed by the query name which is &quot;<strong><em>posts</em></strong>&quot; in this case.</p><pre>{<br>   &quot;<strong>data</strong>&quot;: {<br>     &quot;<strong>posts</strong>&quot;: [<br>       {<br>         &quot;id&quot;: &quot;some-uuid&quot;,<br>         &quot;at&quot;: &quot;2020-07-26T16:10:57.076+0000&quot;,<br>         &quot;caption&quot;: &quot;My latest post!!&quot;,<br>         &quot;mediaUrl&quot;: &quot;http://somecdn/some-image.jpg&quot;,<br>         &quot;location&quot;: &quot;Pune, India&quot;,<br>         &quot;comments&quot;: [<br>            {<br>              &quot;id&quot;: &quot;some-uuid&quot;,<br>              &quot;comment&quot;: &quot;Wow, what a place!!&quot;,<br>              &quot;at&quot;: &quot;2020-07-26T16:11:05.010+0000&quot;,<br>              &quot;by&quot;: &quot;Mahesh&quot;<br>            },<br>            {<br>              &quot;id&quot;: &quot;some-uuid&quot;,<br>              &quot;comment&quot;: &quot;I have been there too!&quot;,<br>              &quot;at&quot;: &quot;2020-07-26T17:01:30.015+0000&quot;,<br>              &quot;by&quot;: &quot;Neeta&quot;<br>            }<br>          ]<br>       },<br>       ... // more posts in similar format<br>     ]<br>   }<br>}</pre><h4>Sample GraphQL Error Response</h4><p>In case of any error, the response would have a list of <strong>errors</strong> and the response would look something like this:</p><pre>{<br>  &quot;errors&quot;: [<br>    {<br>      &quot;errorType&quot;: &quot;SomeException&quot;,<br>      &quot;message&quot;: &quot;Some Error Message&quot; <br>    }<br>  ]<br>}</pre><h4>Mutation:</h4><p>Mutations are used for write operations. Again, in the context of Facebook, an user can share posts, like posts, add comments, delete comments etc. So the type definition for the mutations may look something like this:</p><pre>type <strong>Mutation</strong> {<br>  sharePost(post: Post!): Post<br>  likePost(post: Post!): Post<br>  addComment(postId: ID!, comment: Comment): Comment<br>  deleteComment(commentId: ID!): Comment<br>}</pre><p>We won&#39;t cover examples for the Mutations here, but I would add URLs in the references section.</p><h3>Do I need to use GraphQL?</h3><p>GraphQL provides a complete and understandable description of the data in your API, gives clients<strong> the power to</strong> <strong>ask for exactly what they need and nothing more</strong>, makes it easier to evolve APIs<strong> </strong>over time, and enables powerful developer tools.</p><p>GraphQL has been a popular choice for building<strong> Backends For Frontends(BFFs), </strong>where one needs to aggregate data from multiple data sources to be consumed by their various clients like Web Browsers on Mobile devices, Android App, iOS App, Web Browsers on Desktops/Laptops etc.</p><blockquote>The data required for each of the client(Desktop, Laptop, Mobile) would vary based on the amount of data they can display based on display size of the device. We can create a BFF layer for each type of client or use something like GraphQL which allows the client to ask for exactly what it needs.</blockquote><p>A picture is a worth thousand words. Let&#39;s add a few thousands 😉</p><h4>BFF without GraphQL</h4><p>In this case, all the communication happens using REST and each client has it&#39;’s own BFF layer i.e. one for Web browser, one for Android, one for iOS etc.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*MhfuM38XIOAVJbYXwwZSNQ.png" /></figure><h4>BFF with GraphQL exposed to clients</h4><p>Here the clients are GraphQL aware and they talk to the API using GraphQL. The GraphQL server talks to the microservices using REST.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WAIvjx4RBydeOywNhnrK6Q.png" /></figure><p>One can very well have multiple GraphQL endpoints dedicated for a consumer i.e. you can still have separate GraphQL BFF for Web, Android, iOS etc. Would the duplication of Schema add value?</p><h4>BFF with GraphQL working behind the scenes</h4><p>In this case, we use GraphQL to aggregate the microservices apis but the clients still talk using REST. The clients are not aware of GraphQL and they need not make any change. The GraphQL server still talks to the microservices using REST.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*1gRvwj6wQroAKKnJ5GYf4g.png" /></figure><p>In this case also, you can have multiple BFFs for each device and each talking to multiple GraphQL APIs behind the scenes</p><h4>So do I really need GraphQL?</h4><p>Based on your service clients (if they are internal i.e. a customer service portal, external i.e. a self service portal or an external business to business customer), who controls their source code and the confidence you have on GraphQL, you would fall in one of the above categories for your BFF implementation. If you are not already using GraphQL, give it a try and discover for yourself, if the trade-offs are worth it.</p><h3>Can GraphQL be used beyond Backends For Frontends(BFFs)?</h3><p>We know for sure, GraphQL can be helpful for BFFs but can it go beyond that. Let&#39;’s see if we can use GraphQL for<strong> server-to-server communication</strong>.</p><h4>GraphQL everywhere</h4><p>In this case, you may still have an aggregator GraphQL API which can aggregate the GraphQL schema of multiple microservices and give you a Graph of your entire business model. The aggregator GraphQL server talks to the microservices using GraphQL instead of REST. The microservices also talk to each other using GraphQL.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gC6fchSzdUhQzaqFRsyu_Q.png" /></figure><blockquote>As per Apollo, Appollo Federation is an answer to implementing GraphQL in a microservice architecture.</blockquote><h4>GraphQL and REST</h4><p>You may have some clients where you can&#39;t force them to use GraphQL. So probably you would still have to use REST. Say you are going for GraphQL everywhere, even then, during the transition you may need to support both REST and GraphQL. Let&#39;’s see how it looks</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*d88u6J5a8RSu7zh8DK0WjQ.png" /></figure><h4>GraphQL for Reads and REST for writes</h4><p>One of the possibility is to use GraphQL only for read operations (This is where GraphQL brings a lot of value). The write operations can still be REST. In someway this may look like CQRS working in 2 different protocols for Commands(REST) and Queries (GraphQL). In the world where everyone is making a move towards Serverless architectures, achieving something like this is not very difficult either. Now the real question, is this worth it?</p><h3>Conclusion</h3><p>There are more possible ways of using GraphQL for server to server communication, which is not covered here. At the moment, I have used GraphQL for a very limited server to server communication and like the power it brings. I&#39;m considering to go for GraphQL for READ (within the microservices as well) and still use REST for WRITE. I would like to hear your feedback. Have you have taken this route? Have you successfully used GraphQL beyond BFFs?</p><h3>References</h3><ul><li><a href="https://martinfowler.com/articles/richardsonMaturityModel.html">REST</a> (Martin Fowler)</li><li><a href="https://graphql.org">GraphQL</a></li><li><a href="https://graphql.org/learn/queries/#mutations">GraphQL Mutations</a></li><li><a href="https://philcalcado.com/2015/09/18/the_back_end_for_front_end_pattern_bff.html">Backends For Frontends</a> (Phil Calçado)</li><li><a href="https://samnewman.io/patterns/architectural/bff/">Backends For Frontends</a> (Sam Newman)</li><li><a href="https://martinfowler.com/bliki/CQRS.html">CQRS</a> (Martin Fowler)</li><li><a href="https://www.apollographql.com/blog/apollo-federation-f260cf525d21/">Appollo Federation</a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a1cb34170fff" width="1" height="1" alt="">]]></content><author><name>Girija Swain</name></author><category term="graphql" /><category term="backends-for-frontends" /><category term="rest" /><category term="server-to-server" /><summary type="html"><![CDATA[In this post, we start with a brief introduction to GraphQL and its common industry accepted usage pattern as BFFs(Backends For Frontends). Can it be used beyond that? I would focus around the below questionsWhat is GraphQL?Do I need to use GraphQL?Can GraphQL be used beyond Backends For Frontends(BFFs)?Basic knowledge of REST is a prerequisite for understanding the concepts in this post.What is GraphQL?GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data. So there are 2 components to this. A GraphQL server and a GraphQL client. Both of them talk to each other using GrpahQL query language. GraphQL is transport agnostic and works well over HTTP. The client sends a GraphQL query, the server understands what the client has asked it to do and process the request and sends the response. In the REST world, we all know what CRUD (Create, Read, Update, Delete) stands for and how it works. In the GraphQL world, the reads are Queries and the writes are Mutations. That&#39;s it 😊History:Facebook’s mobile apps have been powered by GraphQL since 2012. A GraphQL spec was open sourced in 2015.Schema:GraphQL has a Schema, which consists of Query (for read operations) and Mutation (for write operations) with it’s own type definitions.schema { query: Query mutation: Mutation}Query:Queries are used for read operations. Let’ take a simple example in the context of Facebook. A facebook user can log in and see multiple posts from their friends with a certain number of comments. An illustrative GraphQL type definition in this case may look something like thistype Query { posts: [Post] # This query fetches list of Posts ... # Other query definitions}type Post { id: ID! # Id of the post at: String! # Time at which it was Posted caption: String! # Caption of the post mediaUrl: String # Url to the image or video shared location: String # Location of the post comments: [Comment] # Comments on the post of type Comment ... # Other properties definition of a post}type Comment { id: ID! # Id of the comment comment: String! # The text of the comment at: String! # Time at which it was Commented by: String! # The user who made the comment ... # Other properties definition of a Comment} Sample GraphQL Query:A sample query to fetch posts with comments for each post would look like the followingquery { posts { id at caption mediaUrl location comments { id comment at by } }}If you look at the above query, we only ask for the required fields and nothing more for the posts as well as the comments for each post. There could be more fields both for posts and comments, which we don&#39;t need and they are not part of the response as well.Sample GraphQL ResponseHere is a sample response for the above mentioned query. Notice the top level key is &quot;data&quot; followed by the query name which is &quot;posts&quot; in this case.{ &quot;data&quot;: { &quot;posts&quot;: [ { &quot;id&quot;: &quot;some-uuid&quot;, &quot;at&quot;: &quot;2020-07-26T16:10:57.076+0000&quot;, &quot;caption&quot;: &quot;My latest post!!&quot;, &quot;mediaUrl&quot;: &quot;http://somecdn/some-image.jpg&quot;, &quot;location&quot;: &quot;Pune, India&quot;, &quot;comments&quot;: [ { &quot;id&quot;: &quot;some-uuid&quot;, &quot;comment&quot;: &quot;Wow, what a place!!&quot;, &quot;at&quot;: &quot;2020-07-26T16:11:05.010+0000&quot;, &quot;by&quot;: &quot;Mahesh&quot; }, { &quot;id&quot;: &quot;some-uuid&quot;, &quot;comment&quot;: &quot;I have been there too!&quot;, &quot;at&quot;: &quot;2020-07-26T17:01:30.015+0000&quot;, &quot;by&quot;: &quot;Neeta&quot; } ] }, ... // more posts in similar format ] }}Sample GraphQL Error ResponseIn case of any error, the response would have a list of errors and the response would look something like this:{ &quot;errors&quot;: [ { &quot;errorType&quot;: &quot;SomeException&quot;, &quot;message&quot;: &quot;Some Error Message&quot; } ]}Mutation:Mutations are used for write operations. Again, in the context of Facebook, an user can share posts, like posts, add comments, delete comments etc. So the type definition for the mutations may look something like this:type Mutation { sharePost(post: Post!): Post likePost(post: Post!): Post addComment(postId: ID!, comment: Comment): Comment deleteComment(commentId: ID!): Comment}We won&#39;t cover examples for the Mutations here, but I would add URLs in the references section.Do I need to use GraphQL?GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools.GraphQL has been a popular choice for building Backends For Frontends(BFFs), where one needs to aggregate data from multiple data sources to be consumed by their various clients like Web Browsers on Mobile devices, Android App, iOS App, Web Browsers on Desktops/Laptops etc.The data required for each of the client(Desktop, Laptop, Mobile) would vary based on the amount of data they can display based on display size of the device. We can create a BFF layer for each type of client or use something like GraphQL which allows the client to ask for exactly what it needs.A picture is a worth thousand words. Let&#39;s add a few thousands 😉BFF without GraphQLIn this case, all the communication happens using REST and each client has it&#39;’s own BFF layer i.e. one for Web browser, one for Android, one for iOS etc.BFF with GraphQL exposed to clientsHere the clients are GraphQL aware and they talk to the API using GraphQL. The GraphQL server talks to the microservices using REST.One can very well have multiple GraphQL endpoints dedicated for a consumer i.e. you can still have separate GraphQL BFF for Web, Android, iOS etc. Would the duplication of Schema add value?BFF with GraphQL working behind the scenesIn this case, we use GraphQL to aggregate the microservices apis but the clients still talk using REST. The clients are not aware of GraphQL and they need not make any change. The GraphQL server still talks to the microservices using REST.In this case also, you can have multiple BFFs for each device and each talking to multiple GraphQL APIs behind the scenesSo do I really need GraphQL?Based on your service clients (if they are internal i.e. a customer service portal, external i.e. a self service portal or an external business to business customer), who controls their source code and the confidence you have on GraphQL, you would fall in one of the above categories for your BFF implementation. If you are not already using GraphQL, give it a try and discover for yourself, if the trade-offs are worth it.Can GraphQL be used beyond Backends For Frontends(BFFs)?We know for sure, GraphQL can be helpful for BFFs but can it go beyond that. Let&#39;’s see if we can use GraphQL for server-to-server communication.GraphQL everywhereIn this case, you may still have an aggregator GraphQL API which can aggregate the GraphQL schema of multiple microservices and give you a Graph of your entire business model. The aggregator GraphQL server talks to the microservices using GraphQL instead of REST. The microservices also talk to each other using GraphQL.As per Apollo, Appollo Federation is an answer to implementing GraphQL in a microservice architecture.GraphQL and RESTYou may have some clients where you can&#39;t force them to use GraphQL. So probably you would still have to use REST. Say you are going for GraphQL everywhere, even then, during the transition you may need to support both REST and GraphQL. Let&#39;’s see how it looksGraphQL for Reads and REST for writesOne of the possibility is to use GraphQL only for read operations (This is where GraphQL brings a lot of value). The write operations can still be REST. In someway this may look like CQRS working in 2 different protocols for Commands(REST) and Queries (GraphQL). In the world where everyone is making a move towards Serverless architectures, achieving something like this is not very difficult either. Now the real question, is this worth it?ConclusionThere are more possible ways of using GraphQL for server to server communication, which is not covered here. At the moment, I have used GraphQL for a very limited server to server communication and like the power it brings. I&#39;m considering to go for GraphQL for READ (within the microservices as well) and still use REST for WRITE. I would like to hear your feedback. Have you have taken this route? Have you successfully used GraphQL beyond BFFs?ReferencesREST (Martin Fowler)GraphQLGraphQL MutationsBackends For Frontends (Phil Calçado)Backends For Frontends (Sam Newman)CQRS (Martin Fowler)Appollo Federation]]></summary></entry><entry><title type="html">SpringBoot + DigitalOcean Droplets</title><link href="https://gsswain.com/2020/07/03/springboot-digitalocean-droplets.html" rel="alternate" type="text/html" title="SpringBoot + DigitalOcean Droplets" /><published>2020-07-03T00:00:00+00:00</published><updated>2020-07-03T00:00:00+00:00</updated><id>https://gsswain.com/2020/07/03/springboot-digitalocean-droplets</id><content type="html" xml:base="https://gsswain.com/2020/07/03/springboot-digitalocean-droplets.html"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*YLJ_Go4vlfU9qDwPpOld3Q.png" /></figure>
<p>In this post, we’ll learn how to build and deploy a simple HelloWorld <strong><em>SpringBoot</em></strong> web app on
    a <strong><em>DigitalOcean Droplets</em></strong> (Virtual Machine). We’ll start by creating a SpringBoot web app,
    package that into a fat JAR (You can skip this step, if are familiar with SpringBoot). After this, we’ll create a
    <strong><em>systemd</em></strong> service file for running the web app. Then we create a Droplet, connect to that
    using SSH, configure the Droplet to run SpringBoot App, upload the artifacts and run and test our SpringBoot web
    app. Finally we clean up the resources.
</p>
<blockquote>Note: <strong>Bela</strong> is my friend and in this post we’ll all say “Hi, Bela!”</blockquote>
<p><strong><em>Table of Contents</em></strong></p>
<ol>
    <li><a href="#section_1">Building a HelloWorld SpringBoot Web App</a></li>
    <li><a href="#section_2">Systemd service file for running the Web App</a></li>
    <li><a href="#section_3">Create a DigitalOcean Droplet</a><br>
        1. <a href="#section_3_1">Create a key pair</a> (We’ll use this
        for accessing the Droplet)<br>
        2. <a href="#section_3_2">Create a project</a> (Optional step - Only if you don’t have
        one)<br>
        3. <a href="#section_3_3">Create a Droplet</a></li>
    <li><a href="#section_4">SSH into the Droplet</a></li>
    <li><a href="#section_5">Configure the Droplet for SpringBoot Web App</a><br>
        1. <a href="#section_5_1">Install JRE in the
            Droplet</a><br>
        2. <a href="#section_5_2">Copy Artifacts into the Droplet</a> (JAR and systemd service file)</li>
    <li><a href="#section_6">Run and Test the SpringBoot Web App</a><br>
        1. <a href="#section_6_1">Run the SpringBoot Web App</a><br>
        2. <a href="#section_6_2">Test the SpringBoot Web App</a></li>
    <li><a href="#section_7">Clean up</a></li>
    <li><a href="#section_8">Resources</a></li>
</ol>

<h3 id="section_1"><strong>Building a HelloWorld SpringBoot Web App</strong></h3>
<p>Go to <a href="https://start.spring.io">Spring Initializr</a>, add the <strong><em>Spring Web</em></strong>
    dependency and click on GENERATE. As of today, the defaults on Spring Initializr are Project type (Maven),
    SpringBoot version (2.3.1), packaging(JAR), Java version (8). ( Also Change the group and artifact name if you would
    like to. I have used <strong><em>com.bela</em></strong> as my group name here)</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*os2sGLaW899yq3OSVotNxA.png" /></figure>
<p>We’ll add a <strong><em>/hello</em></strong> endpoint which returns the string “<strong><em>Hi, Bela!</em></strong>”.
    (I have added the controller in the <em>DemoApplication.java. </em>This can and should be in a different
    file<em>)</em></p>
<pre>@SpringBootApplication<br>public class DemoApplication {<br><br>   public static void main(String[] args) {<br>      SpringApplication.run(DemoApplication.class, args);<br>   }<br><br>   @RestController(&quot;/&quot;)<br>   class HelloWorld {<br>      @GetMapping(&quot;hello&quot;)<br>      public String hello(){<br>         return &quot;Hi, Bela!&quot;;<br>      }<br>   }<br>}</pre>
<p>Run the project on local</p>
<pre>./mvnw spring-boot:run</pre>
<p>Test the <strong><em>/hello</em></strong> endpoint on localhost</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/574/1*TAX2JKQH6Rpb6IGSRRfoWA.png" /></figure>
<p>Now we can build and package the project (This will create the fat JAR
    <strong><em>demo-0.0.1-SNAPSHOT.jar</em></strong> in <strong><em>target</em></strong> folder)
</p>
<pre>./mvnw clean package</pre>
<h3 id="section_2">Systemd service file for running the Web App</h3>
<p>Create a <strong><em>hello-world-spring-boot.service</em></strong> file with the following content.</p>
<pre>[Unit]<br>Description=Hello World Demo Spring Boot<br>After=network.target<br>StartLimitIntervalSec=0<br>[Service]<br>Type=simple<br>Restart=always<br>RestartSec=1<br>User=<strong><em>root</em></strong><br><strong>ExecStart=/usr/bin/java -jar /artifact/demo-0.0.1-SNAPSHOT.jar</strong></pre>
<pre>[Install]<br>WantedBy=multi-user.target</pre>
<blockquote>Note: Use a different user instead of <strong>root. </strong>Here root is used to keep this example simple.
    Also note the JAR absolute path which is <strong>/artifact. </strong>We’ll upload the JAR file into the
    <strong>/artifact</strong> directory of the Droplet. This folder name can be anything. You must ensure the JAR
    exists in the path we specify here.
</blockquote>
<h3 id="section_3">Create a DigitalOcean Droplet</h3>
<p>Droplets are essentially virtual machines (They are like AWS EC2 instances, Azure VMs, Google Compute Engine).</p>
<h4 id="section_3_1">Create a key pair</h4>
<p>Before we create a Droplet, let’s create a key pair to safely access the Droplet. I’ll be using
    <strong><em>ssh-keygen </em></strong>to generate the key pair and store them in a folder named key. (If you are on
    windows, you can follow the link in the resouces section below.)
</p>
<pre>ssh-keygen -t rsa -b 4096 -C “<a href="mailto:your-email@domain.rootdomain">your-email@</a>somedomain.com” -f ./key/id_rsa</pre>
<p>At this point, your folder should look like this</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/692/1*gLTzCSlY-n-OCF3DPm88CA.png" /></figure>
<h4 id="section_3_2">Create a project</h4>
<p>This step is optional. If you already have created a project, move to <a href="#section_3_3">creating a Droplet</a>.<br>If
    you don’t have any project, then create a new project.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AEivt2JWQgXj-3Opmr0nKg.png" /></figure>
<h4 id="section_3_3">Create a Droplet</h4>
<p>Now we create a Droplet by selecting the OS distribution and version, Virtual machine plan, datacenter region, VPC
    Network, SSH Keys, Project. We keep everything default apart from selecting the region to Bangalore and adding our
    ssh keys for access control.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*osh7NRQqAuHvRBolwCZi0Q.png" /></figure>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TUusqoW1XDJWCRkZ55a0gQ.png" /></figure>
<p>Copy the <em>generated </em>public key <strong><em>key/id_rsa.pub </em></strong>into the SSH key content section and
    provide a name for the key.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*cidBNDcXag9-yxL48evV1Q.png" /></figure>
<p>Make sure you select the correct project here, if you have more than one. Now click on
    <strong>Create Droplet</strong>.
</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*tvZl7TR_1vKvOKV0AjmLjw.png" /></figure>
<p>We should see something like this where it shows the Droplet under the resources with the progress indicator in blue.
</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*XsPiJ8D1JBtinKanaHY3tA.png" /></figure>
<p>Once the Droplet is ready, take note of the <strong><em>IP address</em></strong> and copy it as per the below image.
    We’ll use this IP to execute the remaining steps.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*M_1gLlhLJKt_KIyJrjcAoQ.png" /></figure>
<h3 id="section_4"><strong>SSH into the Droplet</strong></h3>
<p>You can use the private key to ssh into the Droplet. Open a terminal window and enter the following command. (Replace
    the IP in bold with the public IP of your Droplet)</p>
<pre>ssh -i key/id_rsa root@<strong>&lt;IP Address of the Droplet&gt;</strong></pre>
<p>e.g. if I replace the IP placeholder with <strong><em>157.245.100.221, </em></strong>then the command would look like
</p>
<pre>ssh -i key/id_rsa root@<strong><em>157.245.100.221</em></strong></pre>
<h3 id="section_5">Configure the Droplet for SpringBoot Web App</h3>
<h4 id="section_5_1">Install JRE in the Droplet</h4>
<p>Run the following commands (This needs to be run from the terminal we used to ssh into the Droplet)</p>
<pre>sudo apt update<br>sudo apt install openjdk-8-jre-headless<br>java -version</pre>
<p>The output of the java -version should look something like this.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/988/1*V1Ee-RxbYVOizj1a_cXKZw.png" /></figure>
<h4 id="section_5_2">Copy Artifacts into the Droplet</h4>
<p>We’ll copy the JAR into <strong><em>/aritifact</em></strong> directory and copy the <strong><em>systemd</em></strong>
    service file to <strong><em>/etc/systemd/system</em></strong> directory</p>
<p>Create a directory named <strong><em>artifact </em></strong>in the root directory of the Droplet</p>
<pre>mkdir /artifact</pre>
<p>Now copy the JAR and the systemd service file into the Droplet. Open a<strong> new terminal window on your local
        system</strong> and run the following command (Remember to replace the IP placeholder in bold with the public IP
    of your Droplet)</p>
<pre>scp -i key/id_rsa demo/target/demo-0.0.1-SNAPSHOT.jar root@<strong>&lt;IP Address of the Droplet&gt;</strong>:/artifact</pre>
<pre>scp -i key/id_rsa hello-world-spring-boot.service <a href="mailto:root@157.245.100.221">root@</a><strong>&lt;IP Address of the Droplet&gt;</strong>:/etc/systemd/system</pre>
<p>e.g. if I replace the IP placeholder with <strong><em>157.245.100.221</em></strong> the command would look like</p>
<pre>scp -i key/id_rsa demo/target/demo-0.0.1-SNAPSHOT.jar root@<strong>157.245.100.221</strong>:/artifact</pre>
<pre>scp -i key/id_rsa hello-world-spring-boot.service <a href="mailto:root@157.245.100.221">root@</a><strong><em>157.245.100.221</em></strong>:/etc/systemd/system</pre>
<h3 id="section_6">Run and Test the SpringBoot Web App</h3>
<h4 id="section_6_1">Run the SpringBoot Web App</h4>
<p>Start the service (This needs to be run from the terminal we used to ssh into the Droplet)</p>
<pre>systemctl start hello-world-spring-boot.service</pre>
<p><strong>Bonus (Optional Step):</strong></p>
<p>You can make sure to bring the service up in case of a Droplet restart, by using the following command in the Droplet
    (Run in the ssh session).</p>
<pre>systemctl enable hello-world-spring-boot.service</pre>
<h4 id="section_6_2">Test the SpringBoot Web App</h4>
<p>Now let’s test our endpoint from within the ssh session</p>
<pre>curl http://localhost:8080/hello</pre>
<p>Seems to be working from the ssh session. Now let’s test using the browser using the public ip. (Use your Droplet IP
    instead of the one shown in the below image i.e. your URL would be http://<strong>&lt;IP Address of the
        Droplet&gt;</strong>:8080/hello)</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/952/1*E9GE03T6k9kCdc0VCA23LQ.png" /></figure>
<p>Phew! now our spring boot service runs on the Droplet. Thanks for being patient and reading till this point. I hope
    this was helpful. Do not forget to read the clean up section to remove the resources we created (Otherwise you’ll be
    chraged for those resources).</p>
<h3 id="section_7"><strong>Clean up</strong></h3>
<p>If you wanted to run this just for trying out DigitalOcean, do not forget to clean up the resources we created.
    Delete the Droplet, Delete the project.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Q-enEJFn9tNZCiAhU-1O7g.png" /></figure>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*bhkt21X_kmO5iBNFVjtoKw.png" /></figure>
<p>For deleting the project, go to the project, then click on the <strong><em>Settings</em></strong> tab and scroll to
    the bottom of the page and click on <strong><em>Delete Project</em></strong> button.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/954/1*cOKr7yRgKEbnXw4GaR0PWw.png" /></figure>
<h3 id="section_8">Resources</h3>
<ul>
    <li><a href="https://spring.io/projects/spring-boot">SpringBoot</a></li>
    <li><a href="https://www.digitalocean.com/products/droplets/">DigitalOcean Droplets</a></li>
    <li><a href="https://en.wikipedia.org/wiki/Systemd">systemd</a></li>
    <li><a
            href="https://www.digitalocean.com/docs/droplets/how-to/add-ssh-keys/">https://www.digitalocean.com/docs/droplets/how-to/add-ssh-keys/</a>
    </li>
    <li><a
            href="https://github.com/GSSwain/spring-boot-on-digital-ocean-droplet">https://github.com/GSSwain/spring-boot-on-digital-ocean-droplet</a>
    </li>
</ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=410b8bbc6fe6" width="1"
    height="1" alt="">]]></content><author><name>Girija Swain</name></author><category term="spring-boot" /><category term="digitalocean" /><category term="droplet" /><category term="cloud" /><category term="virtual-machine" /><summary type="html"><![CDATA[In this post, we’ll learn how to build and deploy a simple HelloWorld SpringBoot web app on a DigitalOcean Droplets (Virtual Machine). We’ll start by creating a SpringBoot web app, package that into a fat JAR (You can skip this step, if are familiar with SpringBoot). After this, we’ll create a systemd service file for running the web app. Then we create a Droplet, connect to that using SSH, configure the Droplet to run SpringBoot App, upload the artifacts and run and test our SpringBoot web app. Finally we clean up the resources. Note: Bela is my friend and in this post we’ll all say “Hi, Bela!” Table of Contents Building a HelloWorld SpringBoot Web App Systemd service file for running the Web App Create a DigitalOcean Droplet 1. Create a key pair (We’ll use this for accessing the Droplet) 2. Create a project (Optional step - Only if you don’t have one) 3. Create a Droplet SSH into the Droplet Configure the Droplet for SpringBoot Web App 1. Install JRE in the Droplet 2. Copy Artifacts into the Droplet (JAR and systemd service file) Run and Test the SpringBoot Web App 1. Run the SpringBoot Web App 2. Test the SpringBoot Web App Clean up Resources]]></summary></entry></feed>